{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7ab5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# import gensim\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36084258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tf.random.set_seed(seed_value)\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e036b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a1221543-b1fd-4225-91c9-1f372ac315e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + \"//dataset_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76624ecc-8bb7-4e52-b95d-1a01cecacb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 10, input_shape = 90): \n",
    "    input_layer = tf.keras.layers.Input(shape = (input_shape))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(1)\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8153ea5-cefc-4075-994d-c51461505e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_word2vec = train_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "95a7d5f5-e03c-4de4-8bea-d4821cc7209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1, h2 = 16,16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2ff179a-2c64-4bae-bfd5-3ce7f4b40fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ann_15 = ann(h1)\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "# ann_15.summary()\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0bf5144e-59f2-413e-af30-39407819094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 90)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                1456      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9c45b5a-9f13-4fd9-b90c-ed94e069b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_word2vec = train_omics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bce5668e-a895-47b4-8f1c-6e5d1fd3c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_20 = ann(h2, 90)\n",
    "\n",
    "\n",
    "\n",
    "# ann_20.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a41f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_1 = ann_15.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0721ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_2 = ann_20.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b2ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = total_weights_1 + total_weights_2 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "999f5e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2947"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "feb2ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch size\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4eea8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_weights = 0.08\n",
    "# var_targets = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b49ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a60a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import invgamma, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd888262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c3355c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b1ce82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7425ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b7959ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1db4063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = ann_15.get_weights()\n",
    "weights_ann_2 = ann_20.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "43a211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1, size_ens): \n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "\n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "\n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, 1)\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "\n",
    "    n_hidden_2 = len(weights_ann_2[0].ravel())\n",
    "\n",
    "    initial_ensembles_1 = initial_ensembles.copy()[:, total_weights_1:(total_weights_1+ total_weights_2)]\n",
    "    \n",
    "    # print(batch_data1.shape[1])\n",
    "    \n",
    "    \n",
    "    hidden_weights_2 = initial_ensembles_1[:,:n_hidden_2].reshape(size_ens, batch_data1.shape[1], h2)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_2 = np.einsum('ij,kjl->kil', batch_data1, hidden_weights_2)\n",
    "\n",
    "    hidden_layer_bias_2 = initial_ensembles[:,n_hidden_2:(n_hidden_2 + h2)].reshape(size_ens, 1,  h2)\n",
    "\n",
    "    hidden_output_2 = hidden_output_2+ hidden_layer_bias_2\n",
    "\n",
    "    n_pred_weights_2 = len(weights_ann_2[2].ravel())\n",
    "\n",
    "    output_weights_2 = initial_ensembles_1[:,(n_hidden_2 + h2):(n_hidden_2 + h2 + n_pred_weights_2) ].reshape(size_ens, h2, 1)\n",
    "\n",
    "\n",
    "    output_2 = np.einsum('ijk,ikl->ijl', hidden_output_2, output_weights_2)\n",
    "\n",
    "\n",
    "    output_layer_bias_2 = initial_ensembles_1[:,(n_hidden_2 + h2 + n_pred_weights_2):(n_hidden_2 + h2 + n_pred_weights_2 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "    final_output_2 = output_2 + output_layer_bias_2\n",
    "\n",
    "\n",
    "    weights_1 = initial_ensembles[:, :total_weights_1]\n",
    "\n",
    "    weights_2 = initial_ensembles[:, total_weights_1:(total_weights_1 + total_weights_2)]\n",
    "\n",
    "\n",
    "    avg_weights = initial_ensembles[:, -1].reshape(-1,1)\n",
    "\n",
    "    avg_weights_sig = expit(avg_weights)\n",
    "    \n",
    "    avg_weights_sig = avg_weights_sig.reshape(avg_weights_sig.shape[0], 1, avg_weights_sig.shape[1])\n",
    "    \n",
    "    complement_weights_sig = 1 - expit(avg_weights)\n",
    "    \n",
    "    complement_weights_sig = complement_weights_sig.reshape(complement_weights_sig.shape[0], 1, complement_weights_sig.shape[1])\n",
    "\n",
    "    final_output_1 = final_output_1*complement_weights_sig\n",
    "    \n",
    "    final_output_2 = final_output_2*avg_weights_sig\n",
    "    \n",
    "    output_1_ravel = final_output_1.reshape(size_ens, final_output_1.shape[1]*final_output_1.shape[2])\n",
    "\n",
    "    output_2_ravel = final_output_2.reshape(size_ens, final_output_2.shape[1]*final_output_2.shape[2])\n",
    "\n",
    "\n",
    "    output_1_ravel = output_1_ravel\n",
    "\n",
    "    output_2_ravel = output_2_ravel\n",
    "\n",
    "\n",
    "\n",
    "    weights_1_add = np.zeros((size_ens, (total_weights_2 - total_weights_1)))\n",
    "\n",
    "\n",
    "\n",
    "    weights_1 = np.hstack((weights_1, weights_1_add))\n",
    "    \n",
    "\n",
    "\n",
    "    stack_1 = np.hstack((output_1_ravel, weights_1, np.repeat(0, size_ens).reshape(-1,1), np.repeat(0, size_ens).reshape(-1,1)))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    stack_2 = np.hstack((output_2_ravel, weights_2, avg_weights, log_sigma_points_1))\n",
    "\n",
    "    \n",
    "    initial_aug_state = np.hstack((stack_1, stack_2)) \n",
    "    \n",
    "\n",
    "    return initial_aug_state , output_1_ravel, output_2_ravel, log_sigma_points_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4e3ef6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0eabfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "10d77915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ebeb0869-7f0b-4f21-be63-0234896af39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fudged_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "23d87ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f5427e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be0ee1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fb492324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_train_logits_second[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0c2dbaec-3249-404a-9971-c2fc17f68356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9cf12935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ef051014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1969c78b-c105-482a-a957-e81329037a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cores = multiprocessing.cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6a062f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "881d1612-f98f-4df6-89b0-90bd2e97de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ac0108fa-359e-4d88-ba02-776a6f19b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6cd29e03-d778-4eeb-98b5-de815840cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cc0be1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b49d0934-faa0-428b-8dc7-e53323a26372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0d5734d0-e75c-436e-bdea-6d5c8223754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "25586772-a3e4-4d5e-b745-6495023e37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "516ae86c-6a46-4d98-9f6b-3eb93f6441de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"..//..//Data//untouched_all_embs_ten_fold.pickle\", \"rb\") as f:\n",
    "    catch_main = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1350b5d2-36dd-4183-a736-6bfcf791b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7ce24ad0-fb33-48cc-9111-b87c993695e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_one_real_world(idx, size_ens, size_drugs = 90, size_omics = 30): \n",
    "    item = catch_main[idx]\n",
    "    a1, a2 = item[0], item[1]\n",
    "    train_drugs_emb, train_gen_expr_emb, train_dna_methyl_emb, train_gen_mut_emb, train_y = a1\n",
    "    test_drugs_emb, test_gen_expr_emb, test_dna_methyl_emb, test_gen_mut_emb, test_y = a2\n",
    "    train_rmse = []\n",
    "    test_rmse = []\n",
    "    train_cov = []\n",
    "    test_cov = []\n",
    "    train_p = []\n",
    "    test_p = []\n",
    "    train_width = []\n",
    "    test_width = []\n",
    "#     from scipy.special import expit\n",
    "    patience_smaller = 0\n",
    "    patience_uns = 0\n",
    "    \n",
    "    print(\"Size_Ens is \" + str(size_ens), flush = True)\n",
    "    \n",
    "    best_train_mae = 100000\n",
    "    \n",
    "    best_train_width = 100000\n",
    "\n",
    "        \n",
    "    X_train_logits_unshuffled = train_y.reshape(-1,1)\n",
    "    train_size = X_train_logits_unshuffled.shape[0]\n",
    "\n",
    "    X_test_logits = test_y.reshape(-1,1)\n",
    "    \n",
    "    ## create training batch chunks\n",
    "    train_idx = list(range(0, len(X_train_logits_unshuffled)))\n",
    "    batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(X_train_logits_unshuffled),batch_size)]\n",
    "\n",
    "    ## generate some augmented variable for iteration 0\n",
    "    initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "    initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "    initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "    initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    exit_iter_no_thresh = 0\n",
    "    log_sigma_points_1 = (np.log(gamma(gamma_param, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "    \n",
    "    train_lstm = train_drugs_emb\n",
    "\n",
    "    test_lstm = test_drugs_emb\n",
    "\n",
    "    pca = PCA(n_components=size_drugs)\n",
    "    train_lstm = pca.fit_transform(train_lstm)\n",
    "    # valid_lstm = pca.transform(valid_lstm)\n",
    "    test_lstm = pca.transform(test_lstm)\n",
    "    \n",
    "    # print(train_lstm.shape)\n",
    "\n",
    "    train_doc2vec_gen_expr = train_gen_expr_emb\n",
    "    test_doc2vec_gen_expr = test_gen_expr_emb\n",
    "    \n",
    "    pca = PCA(n_components=size_omics)\n",
    "    train_doc2vec_gen_expr = pca.fit_transform(train_doc2vec_gen_expr)\n",
    "    test_doc2vec_gen_expr = pca.transform(test_doc2vec_gen_expr)\n",
    "    \n",
    "    train_doc2vec_gen_mut = train_gen_mut_emb\n",
    "    test_doc2vec_gen_mut = test_gen_mut_emb\n",
    "    \n",
    "    pca = PCA(n_components=size_omics)\n",
    "    train_doc2vec_gen_mut = pca.fit_transform(train_doc2vec_gen_mut)\n",
    "    test_doc2vec_gen_mut = pca.transform(test_doc2vec_gen_mut)\n",
    "    \n",
    "    train_doc2vec_dna_methyl = train_dna_methyl_emb\n",
    "    test_doc2vec_dna_methyl = test_dna_methyl_emb\n",
    "    \n",
    "    pca = PCA(n_components=size_omics)\n",
    "    train_doc2vec_dna_methyl = pca.fit_transform(train_doc2vec_dna_methyl)\n",
    "    test_doc2vec_dna_methyl = pca.transform(test_doc2vec_dna_methyl)\n",
    "    \n",
    "    train_drugs = train_lstm\n",
    "    \n",
    "    test_drugs = test_lstm\n",
    "    \n",
    "    train_omics = np.hstack((train_doc2vec_gen_expr, train_doc2vec_gen_mut, train_doc2vec_dna_methyl))\n",
    "\n",
    "    test_omics = np.hstack((test_doc2vec_gen_expr, test_doc2vec_gen_mut, test_doc2vec_dna_methyl))\n",
    "    \n",
    "    \n",
    "    train_lstm = train_drugs\n",
    "    test_lstm = test_drugs\n",
    "    \n",
    "    train_doc2vec = train_omics\n",
    "    test_doc2vec = test_omics\n",
    "    \n",
    "    best_coverage_train = 0\n",
    "    \n",
    "    start = datetime.now()\n",
    "    \n",
    "    for iter1 in range(0,500):\n",
    "        random_idx = random.sample(range(0,train_lstm.shape[0]), train_lstm.shape[0])\n",
    "        train_valid_lstm =train_lstm[random_idx, :]\n",
    "        train_valid_doc2vec = train_doc2vec[random_idx, :]\n",
    "        X_train_logits = X_train_logits_unshuffled[random_idx, :]\n",
    "        # start_inner = datetime.now()\n",
    "        for batch_idx in batch_chunks:\n",
    "            \n",
    "            batch_data = train_valid_lstm[batch_idx,:]\n",
    "            # print(batch_data.shape)\n",
    "            batch_data1 = train_valid_doc2vec[batch_idx,:]\n",
    "            # print(batch_data1.shape)\n",
    "            batch_targets = X_train_logits[batch_idx,:]\n",
    "            \n",
    "            # print(batch_targets.shape)\n",
    "            \n",
    "            # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "            column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "            H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data1, batch_data, initial_ensembles, log_sigma_points_1, size_ens)\n",
    "            \n",
    "            # print(current_aug_state.shape)\n",
    "            \n",
    "            \n",
    "            var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "            var_targets_vec = var_targets_vec\n",
    "            \n",
    "            # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "            current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "            G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "            scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "            temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "            temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "\n",
    "            R_t1 = var_targetsw*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "            measurement_error1 = mvn(np.repeat(0,current_aug_state.shape[1]), R_t1).rvs(current_aug_state.shape[0])\n",
    "        \n",
    "            for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "                var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "                R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "                measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "                target_current = batch_targets + measurement_error\n",
    "                \n",
    "                # print(target_current.shape)\n",
    "                \n",
    "                K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "                \n",
    "                # print(K_t.shape)\n",
    "\n",
    "                current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "                \n",
    "                current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] + measurement_error1[ensemble_idx,:]\n",
    "\n",
    "            weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "            weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "            initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "            log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "            avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "            complement = 1-avg_betas\n",
    "\n",
    "\n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(train_doc2vec, train_lstm, initial_ensembles, log_sigma_points_1, size_ens)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, train_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_train = initial_targets\n",
    "            \n",
    "            initial_targets_train_mean = initial_targets_train.mean(0)\n",
    "            \n",
    "            li = np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width_train = np.mean(width)\n",
    "            \n",
    "            # interim = np.vstack((catch_train_probs[idx] , catch_valid_probs[idx] ))\n",
    "        \n",
    "            interim = (X_train_logits_unshuffled)\n",
    "            \n",
    "            ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "            coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "            train_mae = np.sqrt(mean_squared_error(interim, initial_targets_train_mean))\n",
    "            \n",
    "            # plt.scatter(interim, initial_targets_train_mean)\n",
    "            # plt.show()\n",
    "            \n",
    "            stats_pearson_train = stats.pearsonr(interim.reshape(interim.shape[0],),\n",
    "                                           initial_targets_train_mean.reshape(initial_targets_train_mean.shape[0],))\n",
    "\n",
    "            # train_mae = np.sqrt(np.mean(np.abs(interim.ravel() - initial_targets_train_mean.ravel())**2))\n",
    "        \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_doc2vec, test_lstm, initial_ensembles, log_sigma_points_1, size_ens)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, test_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_test = initial_targets\n",
    "            \n",
    "            # initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "            initial_targets_test_mean = initial_targets_test.mean(0)\n",
    "            \n",
    "            li = np.percentile(initial_targets_test, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_test, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width = np.mean(width)\n",
    "            \n",
    "            catch_test_probs = (X_test_logits)\n",
    "            \n",
    "            ind_test = (catch_test_probs >= li) & (catch_test_probs <= ui)\n",
    "                        \n",
    "            coverage_test = np.mean(ind_test.ravel())    \n",
    "\n",
    "            \n",
    "            test_mae = np.sqrt(mean_squared_error(catch_test_probs, initial_targets_test_mean))\n",
    "\n",
    "            stats_pearson = stats.pearsonr(catch_test_probs.reshape(catch_test_probs.shape[0],),\n",
    "                                           initial_targets_test_mean.reshape(initial_targets_test_mean.shape[0],))\n",
    "\n",
    "            start_inner_e = datetime.now()\n",
    "            total = (start_inner_e- start_inner)\n",
    "            time_taken = total.seconds/60.0\n",
    "            print(time_taken)\n",
    "            \n",
    "            train_rmse.append(train_mae)\n",
    "            test_rmse.append(test_mae)\n",
    "            train_cov.append(coverage_train)\n",
    "            test_cov.append(coverage_test)\n",
    "            train_p.append(stats_pearson_train)\n",
    "            test_p.append(stats_pearson)\n",
    "            train_width.append(avg_width_train)\n",
    "            test_width.append(avg_width)\n",
    "            \n",
    "            if  train_mae < best_train_mae: \n",
    "                patience = 0\n",
    "                best_train_mae = train_mae\n",
    "                # best_valid_mae = valid_mae\n",
    "                best_test_mae = test_mae\n",
    "                exit_iter_no_thresh = iter1\n",
    "                best_test_preds = initial_targets_test\n",
    "                patience_smaller = 0\n",
    "                best_train_coverage = coverage_train\n",
    "                # best_valid_coverage = coverage_valid\n",
    "                best_test_coverage = coverage_test\n",
    "                best_train_width = avg_width_train\n",
    "                # best_valid_width = avg_width_valid\n",
    "                best_test_width = avg_width\n",
    "                best_drugs_weight = np.mean(complement)\n",
    "                best_r_test = stats_pearson[0]\n",
    "                best_r_train = stats_pearson_train[0]\n",
    "                # best_r_valid = stats_pearson_valid[0]\n",
    "                best_initial_ensembles = initial_ensembles\n",
    "                best_log_sigma_points_1 = log_sigma_points_1\n",
    "                best_initial_targets_test_mean = initial_targets_test_mean\n",
    "                best_li = li\n",
    "                best_ui = ui\n",
    "            else:\n",
    "                patience += 1\n",
    "                \n",
    "            print(\"epoch \"+ str(iter1))\n",
    "            print(\"patience \"+ str(patience))\n",
    "            print(\"train mae is \" + str(train_mae))\n",
    "            # print(\"valid mae is \" + str(valid_mae))\n",
    "            print(\"test mae is \" + str(test_mae))\n",
    "        \n",
    "            print(\"train coverage is \"+ str(coverage_train))\n",
    "            # print(\"valid coverage is \"+ str(coverage_valid))\n",
    "            print(\"test coverage is \"+ str(coverage_test))\n",
    "            \n",
    "            print(\"train width is \" + str(avg_width_train))\n",
    "            # print(\"valid width is \" + str(avg_width_valid))  \n",
    "            print(\"test width is \" + str(avg_width))\n",
    "            \n",
    "            print(\"drugs weight is \" + str(np.mean(complement)))\n",
    "            print(\"pearson r train is \" + str(stats_pearson_train[0]))\n",
    "            # print(\"pearson r valid is \" + str(stats_pearson_valid[0]))\n",
    "            print(\"pearson r test is \" + str(stats_pearson[0]))\n",
    "            \n",
    "            \n",
    "                \n",
    "            if patience >= threshold: \n",
    "                break\n",
    "                \n",
    "        if patience >= threshold: \n",
    "                break\n",
    "            \n",
    "    \n",
    "    # print(best_valid_mae, best_valid_coverage, best_valid_width,best_r_valid, flush = True)\n",
    "    print(best_test_mae, best_test_coverage, best_test_width,best_r_test, flush = True)\n",
    "    end = datetime.now()\n",
    "    total = (end- start)\n",
    "    time_taken = total.seconds/60.0\n",
    "    return size_ens, best_train_mae, best_test_mae, best_train_coverage, best_test_coverage,  \\\n",
    "    best_train_width , best_test_width,  best_drugs_weight, best_r_train, best_r_test, exit_iter_no_thresh, time_taken, best_initial_ensembles, best_log_sigma_points_1, [X_test_logits.tolist(), best_initial_targets_test_mean.tolist()], \\\n",
    "    [best_li.tolist(), best_ui.tolist()], train_rmse, test_rmse, train_cov, test_cov, train_p, test_p, train_width, test_width \n",
    "        \n",
    "    # print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "245e9a9d-00bd-49f2-8333-3de5fe04dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_weights =0.5\n",
    "gamma_param = 500\n",
    "var_targetsw = 0.0001\n",
    "reduction = 15\n",
    "shape_needed = total_weights//reduction\n",
    "# size_ens = 196\n",
    "size_ens = int(shape_needed)\n",
    "batch_size = 1024\n",
    "threshold = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "14c50dce-8fef-4bce-b3e2-d673593b2453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "835d8e43-017f-45b4-a42a-f4bb88c052fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size_Ens is 196\n",
      "1.7\n",
      "epoch 0\n",
      "patience 0\n",
      "train mae is 3.38588080186319\n",
      "test mae is 3.2984375078691395\n",
      "train coverage is 1.0\n",
      "test coverage is 1.0\n",
      "train width is 351.1701440820467\n",
      "test width is 350.73402001194376\n",
      "drugs weight is 0.4578670948283947\n",
      "pearson r train is 0.09799389875483445\n",
      "pearson r test is 0.1154590216783039\n",
      "3.3333333333333335\n",
      "epoch 0\n",
      "patience 1\n",
      "train mae is 3.4296928531442745\n",
      "test mae is 3.357525362578131\n",
      "train coverage is 1.0\n",
      "test coverage is 1.0\n",
      "train width is 130.0117435998182\n",
      "test width is 129.72415842777318\n",
      "drugs weight is 0.3961140742306601\n",
      "pearson r train is 0.13497806708756863\n",
      "pearson r test is 0.1191181708709663\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m size_ens,best_train_mae, best_test_mae, best_train_coverage, best_test_coverage,  \\\n\u001b[0;32m----> 2\u001b[0m     best_train_width , best_test_width,  best_drugs_weight, best_r_train, best_r_test, exit_iter_no_thresh, time_taken, best_initial_ensembles, best_log_sigma_points_1, _, _, train_rmse, test_rmse, train_cov, test_cov, train_p, test_p, train_width, test_width \u001b[38;5;241m=\u001b[39m \u001b[43mrep_one_real_world\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_ens\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[101], line 152\u001b[0m, in \u001b[0;36mrep_one_real_world\u001b[0;34m(idx, size_ens, size_drugs, size_omics)\u001b[0m\n\u001b[1;32m    148\u001b[0m var_targets1 \u001b[38;5;241m=\u001b[39m var_targets_vec[ensemble_idx,:]\n\u001b[1;32m    150\u001b[0m R_t \u001b[38;5;241m=\u001b[39m var_targets1\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39midentity(batch_targets\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 152\u001b[0m measurement_error \u001b[38;5;241m=\u001b[39m \u001b[43mmvn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_targets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_targets1\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midentity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_targets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    154\u001b[0m target_current \u001b[38;5;241m=\u001b[39m batch_targets \u001b[38;5;241m+\u001b[39m measurement_error\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# print(target_current.shape)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/enkf/lib/python3.11/site-packages/scipy/stats/_multivariate.py:873\u001b[0m, in \u001b[0;36mmultivariate_normal_frozen.rvs\u001b[0;34m(self, size, random_state)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrvs\u001b[39m(\u001b[38;5;28mself\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/enkf/lib/python3.11/site-packages/scipy/stats/_multivariate.py:753\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.rvs\u001b[0;34m(self, mean, cov, size, random_state)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cov_object, _covariance\u001b[38;5;241m.\u001b[39mCovViaPSD):\n\u001b[1;32m    752\u001b[0m     cov \u001b[38;5;241m=\u001b[39m cov_object\u001b[38;5;241m.\u001b[39mcovariance\n\u001b[0;32m--> 753\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultivariate_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m     out \u001b[38;5;241m=\u001b[39m _squeeze_output(out)\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32mmtrand.pyx:4155\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/enkf/lib/python3.11/site-packages/numpy/linalg/linalg.py:1657\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n_s\n\u001b[1;32m   1656\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1657\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1658\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1659\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "size_ens,best_train_mae, best_test_mae, best_train_coverage, best_test_coverage,  \\\n",
    "    best_train_width , best_test_width,  best_drugs_weight, best_r_train, best_r_test, exit_iter_no_thresh, time_taken, best_initial_ensembles, best_log_sigma_points_1, _, _, train_rmse, test_rmse, train_cov, test_cov, train_p, test_p, train_width, test_width = rep_one_real_world(0, size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72568e2d-bb4d-4b75-b133-57a26a359814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_actual_preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d6db30-5931-4841-beeb-8c7169e0704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(test_actual_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8981ee-053b-44e7-b05b-c3fc788b12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_actual_preds, best_li_ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4a1add-dfd1-4092-8ce3-1cdc491fc6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1126d3c-2377-428e-a8b1-6a849b16828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_actual_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737ad8b-a1ba-41fe-90cb-d570a7d29a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_li_ui[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5796dcd-701f-468f-85d1-13ec45f5fcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8af807-7147-4bb1-a651-e5c64ad9889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch = Parallel(n_jobs = 14, backend = \"loky\", verbose = 8)(delayed(rep_one_real_world)(idx, size_ens) for idx in range(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6784f03-c726-4b0e-9d06-63d28b8dcf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Preds_with_PCA_proper_CV_no_valid_all_features_diff_size_ens\" + \".pkl\", 'wb') as f:\n",
    "    pickle.dump(catch, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7bd56-f7ce-417f-a186-0dba799fa59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Preds_with_PCA_proper_CV_no_valid_all_features_diff_size_ens\" + \".pkl\", 'rb') as f:\n",
    "    catch = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9f0926-cec8-4079-aaa9-cb6d390cd128",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['size_ens','best_train_mae', 'best_test_mae', 'best_train_coverage', 'best_test_coverage',  \\\n",
    "    'best_train_width' , 'best_test_width',  'best_drugs_weight', 'best_r_train', 'best_r_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfab788b-6557-4725-8726-9f0fd85770c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_df = pd.DataFrame(catch).iloc[:,:len(col_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9acb09-2976-4da5-92e9-13ae53f189ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_df.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3618be7e-e24a-4261-a2b5-5c25211266dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_df.columns = ['best_train_mae', 'best_test_mae', 'best_train_coverage', 'best_test_coverage',  \\\n",
    "#     'best_train_width' , 'best_test_width',  'best_drugs_weight', 'best_r_train', 'best_r_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75057773-997e-485c-913d-cb7e6161ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e86f48-9582-4d40-a692-7f86d4512a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(catch_df['size_ens'], catch_df['best_train_mae'])\n",
    "plt.plot(catch_df['size_ens'], catch_df['best_test_mae'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c192a478-9eb0-49e8-9fab-60fd47229cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(catch_df['size_ens'], catch_df['best_train_coverage'])\n",
    "plt.plot(catch_df['size_ens'], catch_df['best_test_coverage'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ea4a9-4d1f-458b-8312-8dac83b04107",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(catch_df['size_ens'], catch_df['best_train_width'])\n",
    "plt.plot(catch_df['size_ens'], catch_df['best_test_width'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce4f66-a9f4-443a-8931-3b0fd46c1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(catch_df['size_ens'], catch_df['best_r_train'])\n",
    "plt.plot(catch_df['size_ens'], catch_df['best_r_test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed4d01-85f8-45b3-be45-1dc72c7f8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_df = []\n",
    "for i in range(0, len(catch)): \n",
    "    item = catch[i]\n",
    "    size_ens = item[0]\n",
    "    train_rmse = item[-7]\n",
    "    test_rmse = item[-8]\n",
    "    df = pd.DataFrame({\"Train_RMSE\": train_rmse, \n",
    "                      \"Test_RMSE\": test_rmse})\n",
    "    df[\"size_ens\"] = size_ens\n",
    "    df[\"update_iteration\"] = np.array(range(0, df.shape[0])) + 1\n",
    "    catch_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b493d-e5af-4edc-9fd7-a2893f8c632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_df = pd.concat(catch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31516ecf-cebd-41cb-905c-b40943966b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525acd32-a2ac-4031-9f79-4c24ef751b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_df = catch_df[catch_df[\"size_ens\"] != 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f88ee96-4c9a-46ae-97de-4e116e5fa2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010b4a8-4641-478c-a5aa-375bbdaee8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [ 50, 100, 200, 300, 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a8c7d-9327-4a16-98ff-cc0b462e8d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_df = catch_df[catch_df[\"size_ens\"].isin(sizes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec020b5b-c412-44b8-b5de-67a5167b8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logical_ids = [True if (float(size_ens)%100) == 0 else False for size_ens in catch_df['size_ens'].values ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce5a36-9fdc-473d-af35-e8109dd91a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_df[\"size_ens\"] = catch_df[\"size_ens\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0809a8-5304-4950-9669-728e2d2853bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5606de3-5df6-4dc4-9489-df4941663d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af904d83-fa57-4f10-8e20-f2ae48cecfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5518d6f-af49-4d43-8e43-70a9ea88a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (6,4))\n",
    "sns.lineplot(data=catch_df, x=\"update_iteration\", y=\"Train_RMSE\", hue=\"size_ens\", linewidth = 3)\n",
    "plt.xlabel(\"Update Iteration\", fontsize = 15, fontweight = \"bold\")\n",
    "plt.ylabel(\"Train RMSE\", fontsize = 15, fontweight = \"bold\")\n",
    "plt.xticks(fontsize = 10, fontweight = \"bold\")\n",
    "plt.yticks(fontsize = 10, fontweight = \"bold\")\n",
    "leg = plt.legend(title = \"Ensemble Size\",fontsize=10, prop =  {'weight':'bold'}, labelcolor = \"black\", \n",
    "                title_fontproperties=  {'weight':'bold'})\n",
    "for legobj in leg.legend_handles:\n",
    "    legobj.set_linewidth(3.0)\n",
    "fig.savefig('Plots/Different_Ensemble_Size.pdf', bbox_inches='tight', format = \"pdf\")\n",
    "fig.savefig('Plots/Different_Ensemble_Size.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426ce65c-58c6-495c-8900-36d87b062123",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6,3))\n",
    "sns.lineplot(data=catch_df, x=\"update_iteration\", y=\"Test_RMSE\", hue=\"size_ens\", linewidth = 4)\n",
    "plt.xlabel(\"Update Iteration\", fontsize = 15, fontweight = \"bold\")\n",
    "plt.ylabel(\"Test RMSE\", fontsize = 15, fontweight = \"bold\")\n",
    "plt.xticks(fontsize = 10, fontweight = \"bold\")\n",
    "plt.yticks(fontsize = 10, fontweight = \"bold\")\n",
    "leg = plt.legend(title = \"Ensemble Size\",fontsize=10, prop =  {'weight':'bold'}, labelcolor = \"black\", \n",
    "                title_fontproperties=  {'weight':'bold'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba988f7f-d38b-44e0-a31f-9851b5f12900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_df['best_drugs_weight'] = 1 - catch_df['best_drugs_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad9fb9a-71d7-453f-9eca-84e8ee7e11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce27df-65b3-4d71-8230-f5d083e70c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components = test_omics.shape[1])\n",
    "# pca.fit(train_drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ff7a1-4088-40c7-9fd7-a97e74c96f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_drugs = pca.transform(test_drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494d5ae5-5e7a-4e2b-b470-4b71b369345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_drugs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1480a7-ea4d-4046-aee7-2eb00c324076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_test_catch = []\n",
    "# test_catch = []\n",
    "# li_catch = []\n",
    "# ui_catch = []\n",
    "# for i in range(0,6):\n",
    "#     preds = catch[i][-2][1]\n",
    "#     actual = catch[i][-2][0]\n",
    "#     preds_test_catch.append(preds)\n",
    "#     test_catch.append(actual)\n",
    "# #     best_log_sigma_points_1 = catch[i][-3]\n",
    "# #     current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_omics, test_drugs, params, best_log_sigma_points_1)\n",
    "            \n",
    "# #     initial_targets_test = column_mod_11 + column_mod_21\n",
    "            \n",
    "# #     initial_targets_test = initial_targets_test.reshape(size_ens, test_omics.shape[0],1)\n",
    "            \n",
    "# #     initial_targets_test_mean = initial_targets_test.mean(0)\n",
    "    \n",
    "#     # preds_test_catch.append(preds)\n",
    "    \n",
    "#     li = catch[i][-1][0]\n",
    "#     li_catch.append(li)\n",
    "            \n",
    "#     ui = catch[i][-1][1]\n",
    "#     ui_catch.append(ui)\n",
    "            \n",
    "# #     width = ui - li\n",
    "            \n",
    "# #     avg_width = np.mean(width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d409df-f7ea-457c-8328-c4a8dd2a1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_test_catch = [inner for item in preds_test_catch for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87e80d2-b7c8-422f-ae01-8a8090e1703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_catch = [inner for item in test_catch for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb71411d-6e3b-44d3-94bb-7d8dc7cba206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# li_catch =  [inner for item in li_catch for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dbeab3-5fd7-4b5e-b31b-b8cad9facdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ui_catch =  [inner for item in ui_catch for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9c72d-01e9-4e3c-a4cb-c4c398f9c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f961636-d73f-4641-8ac9-8bfdaef5fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_preds = np.array(preds_test_catch).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd644b6-40c2-4a51-926e-6b8fca198cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f421979d-9a9f-4b36-b1a0-b818dc5f9193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e776f-a5a7-4bce-81c2-31e171c3cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_omics, test_drugs, best_initial_ensembles, best_log_sigma_points_1)\n",
    "            \n",
    "# initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "# initial_targets = initial_targets.reshape(size_ens, test_omics.shape[0],1)\n",
    "            \n",
    "# initial_targets_test = initial_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea92bf9-1992-4f0e-8b1f-62a0ed8ed4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "# initial_targets_test_mean = initial_targets_test.mean(0)\n",
    "            \n",
    "# li = np.percentile(initial_targets_test, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "# ui = np.percentile(initial_targets_test, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "# width = ui - li\n",
    "            \n",
    "# avg_width = np.mean(width)\n",
    "            \n",
    "# catch_test_probs = (y_test)\n",
    "            \n",
    "# ind_test = (catch_test_probs >= li) & (catch_test_probs <= ui)\n",
    "                        \n",
    "# coverage_test = np.mean(ind_test.ravel())    \n",
    "\n",
    "            \n",
    "# test_mae = np.sqrt(mean_squared_error(catch_test_probs, initial_targets_test_mean))\n",
    "\n",
    "# stats_pearson = stats.pearsonr(catch_test_probs.reshape(catch_test_probs.shape[0],),\n",
    "#                                            initial_targets_test_mean.reshape(initial_targets_test_mean.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03b7d8-504b-4fd2-bc7b-b8bac7a2bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c950c80-c06d-42f5-938a-699658ddee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string = \"Real_World_EnKF_DeepCDR_\" + \"Neurons_\" + str(h1)  + \"_Gamma_\" +  str(gamma_param) +  \"_var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e559f-315e-4d51-a113-effe6695dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string = \"First_Three_Real_World_EnKF_DeepCDR_\" + \"Neurons_\" + str(h1)  + \"_Gamma_\" +  str(gamma_param) +  \"_var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213b5a0-b128-4d90-8eaf-ef7058c2e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages = [best_train_mae, best_valid_mae, best_test_mae, best_train_coverage, best_test_coverage, best_valid_coverage, best_test_coverage, \\\n",
    "#     best_train_width, best_valid_width , best_test_width, best_drugs_weight, best_r_train, best_r_valid, best_r, exit_iter_no_thresh, time_taken, best_initial_ensembles, best_log_sigma_points_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1027fa-cc7a-4adf-8a6a-db23a1d6323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_train_mae, best_valid_mae, best_test_mae, best_train_coverage, best_test_coverage, best_valid_coverage, best_test_coverage, \\\n",
    "#     best_train_width, best_valid_width , best_test_width, (1-best_drugs_weight), best_r_train, best_r_valid, best_r, exit_iter_no_thresh, time_taken, best_initial_ensembles, best_log_sigma_points_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f11d9-de11-4880-be84-4340352ce23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"Preds_Mutation_Methylation\" + \".pkl\", 'wb') as f:\n",
    "#     pickle.dump(catch_coverages, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80681cc-ed49-44c9-9373-52944bc8d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig  = plt.figure()\n",
    "# plt.scatter(y_test, initial_targets_test_mean, alpha = 0.5)\n",
    "# plt.axline((0,0), slope = 1, c = \"black\", linewidth = 3)\n",
    "# plt.xlabel(\"Observed Log IC50\", fontweight = \"bold\", fontsize = 15)\n",
    "# plt.ylabel(\"MEnKF-ANN Predicted Log IC50\", fontweight = \"bold\", fontsize = 15)\n",
    "# plt.xticks(fontsize = 15, fontweight = \"bold\")\n",
    "# plt.yticks(fontsize = 15, fontweight = \"bold\")\n",
    "# fig.savefig('Plots/Avg_Smile_Weight_Tajectory.pdf', bbox_inches='tight', format = \"pdf\")\n",
    "# fig.savefig('Plots/Avg_Smile_Weight_Tajectory.png', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8200e5-b784-49c8-9ae9-fd7ee5a2e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f27b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647980a7-9ae3-4c5c-b25c-2e37b6a84679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = pd.DataFrame(catch_coverages[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e061792a-e589-486e-b8d2-336622f6bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa101efc-351b-4645-87a3-f008abf1ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77536655-0afd-4976-980a-fa7a28b55201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8cefbd-9076-469e-a5dc-dc4637846308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = check.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8596dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1dcac-24b2-45e7-ae4c-e55eca90a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\", \"train_coverage\", \"train_width\", \"test_coverage\", \"test_width\", \"exit_iter\", \"time_taken\", \"avg_width_alginate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc699633-60c4-4774-93ef-e90160803672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\", \"train_coverage\", \"train_width\", \"test_coverage\", \"test_width\", \"drug_weight\" , \"pearson_correlation\" ,\"exit_iter\", \"time_taken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089a2ab-43f9-4e24-a7ed-add7bdc14156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = [inner for item in true_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65492b8d-d7e4-4375-8577-d79a633680b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkf_preds = [inner for item in enkf_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19776731-14c7-43c3-bd48-163aa67e2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(np.abs(np.array(true_preds)-np.array(enkf_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebada74-6fe8-4f58-a939-87ca7399aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(enkf_preds,true_preds, alpha=0.5)\n",
    "# plt.xlabel(\"EnKF Predictions\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.ylabel(\"LSTM Predictions\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.xticks( fontsize = 10, fontweight = \"bold\")\n",
    "# plt.yticks( fontsize = 10, fontweight = \"bold\")\n",
    "# plt.axline((0, 0), slope=1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd706672-8fd1-4f54-88a2-d377f1b2d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead27b05-299e-49dc-bb97-236a18cd05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_preds = []\n",
    "# for i in range(0, catch_coverages[cur_idx][-1].shape[1]):\n",
    "#     enkf_preds = catch_coverages[cur_idx][-1][:,i,:]\n",
    "#     enkf_preds_df = pd.DataFrame(enkf_preds)\n",
    "#     enkf_preds_df[\"Test_Sample_ID\"] = i \n",
    "#     enkf_preds_df.columns = [\"EnKF_Preds\", \"Test_Sample_ID\"]\n",
    "#     catch_preds.append(enkf_preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f88a3c-8152-4b54-8eea-761701d7b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_preds_df = pd.concat(catch_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614c144-29c3-451d-a6c6-a624aa4096a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f52dcf-cc5b-4af0-b495-9c0601729154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = expit(catch1[cur_idx][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51405252-c830-4c95-90d8-e42cffcae59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.figure(figsize = (10,10))\n",
    "# fig = sns.boxplot(catch_preds_df, x=\"Test_Sample_ID\", y=\"EnKF_Preds\", showfliers=False)\n",
    "# plt.scatter(range(0, filtered_df.shape[0]), filtered_df, c = \"black\", s = 50)\n",
    "# plt.xlabel(\"Test Sample ID\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.ylabel(\"EnKF Predictions\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.xticks(fontsize = 10, fontweight = \"bold\")\n",
    "# plt.yticks(fontsize = 10, fontweight = \"bold\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ef63f-a716-4006-8923-39df160647d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = [i for i in range(0, filtered_df.shape[0]) if filtered_df[i] < 0.5]\n",
    "# ids_more = [i for i in range(0, filtered_df.shape[0]) if filtered_df[i] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0976b8bc-6faa-4c8e-a9d1-3b666d9435e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_preds_df.groupby(\"Test_Sample_ID\").quantile(q = [0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64886e1a-d858-4ea8-9cc4-51ab0b072286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_preds_df_filtered = catch_preds_df[catch_preds_df[\"Test_Sample_ID\"].isin(ids_more)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecec8de-d825-4191-9f35-705382466d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_true = filtered_df[ids_more,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a9f6b-a286-4855-8530-2c2d71d08737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.figure(figsize = (10,10))\n",
    "# fig = sns.boxplot(catch_preds_df_filtered, x=\"Test_Sample_ID\", y=\"EnKF_Preds\", showfliers=False)\n",
    "# plt.scatter(range(0, filtered_true.shape[0]), filtered_true, c = \"black\", s = 50)\n",
    "# plt.xlabel(\"Test Sample ID\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.ylabel(\"EnKF Predictions\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.xticks(fontsize = 10, fontweight = \"bold\")\n",
    "# plt.yticks(fontsize = 10, fontweight = \"bold\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec177a9b-74aa-4458-a88e-a8b1ab1deff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_preds_df_filtered = catch_preds_df[catch_preds_df[\"Test_Sample_ID\"].isin(ids)]\n",
    "# filtered_true = filtered_df[ids,:]\n",
    "# # plt.figure(figsize = (10,10))\n",
    "# fig = sns.boxplot(catch_preds_df_filtered, x=\"Test_Sample_ID\", y=\"EnKF_Preds\", showfliers=False)\n",
    "# plt.scatter(range(0, filtered_true.shape[0]), filtered_true, c = \"black\")\n",
    "# plt.xlabel(\"Test Sample ID\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.ylabel(\"EnKF Predictions\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.xticks(fontsize = 10, fontweight = \"bold\")\n",
    "# plt.yticks(fontsize = 10, fontweight = \"bold\")\n",
    "# plt.show()\n",
    "# # plt.ylim((0.9,1.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
