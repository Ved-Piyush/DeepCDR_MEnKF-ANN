{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ab5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# os.chdir(r\"D://Proposal_Defense//Simulations\")\n",
    "# from Utils.Script_utils import get_data_splits, first_LSTM_training, get_data_splits_old_algo\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36084258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tf.random.set_seed(seed_value)\n",
    "import multiprocessing\n",
    "# for later versions: \n",
    "# tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "# from keras import backend as K\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e036b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aba28b2-8ac3-4f34-90cd-f89214f63110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"high_level_substr\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0db48ca-0165-40d8-9bdc-2dcc0bd77efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alginate_doc2vec_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02c4f20-faf2-4e10-86f6-9ca8a295b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"high_level_substr\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1221543-b1fd-4225-91c9-1f372ac315e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + \"//dataset_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd7d977-20bc-4012-a710-291b706cf0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## read in all the drug features\n",
    "# ## for train test and valid\n",
    "train_drugs = np.load(path + \"//\" + \"train_drug.npy\")\n",
    "# valid_drugs = np.load(path + \"//\" + \"valid_drug.npy\")\n",
    "# test_drugs = np.load(path + \"//\" + \"test_drug.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c9e28e-57e1-4989-9377-779597ab9187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## read in all the omics features\n",
    "# ## for train test and valid\n",
    "train_omics = np.load(path + \"//\" + \"train_omics.npy\")[:,:30]\n",
    "# valid_omics = np.load(path + \"//\" + \"valid_omics.npy\")\n",
    "# test_omics = np.load(path + \"//\" + \"test_omics.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "650a3031-0121-4457-8d37-ed9cc74ab1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## read in all the labels \n",
    "# ## for train test and valid\n",
    "# y_train = np.load(path + \"//\" + \"train_y.npy\")\n",
    "# y_valid = np.load(path + \"//\" + \"valid_y.npy\")\n",
    "# y_test = np.load(path + \"//\" + \"test_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16b2eaeb-68be-4fd1-83c6-e87eee1090b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_drugs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "959e7a79-da91-43f9-9fbe-f4c3a3f4c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_drugs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05b71c4c-55c5-44d2-8248-aca4318bfd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_drugs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4da7a93c-628e-48cb-9d2b-215a4803423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fc3d495-3915-4a91-808b-a33d74336cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8454584-dc3b-47b8-8fec-edd993cca409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76624ecc-8bb7-4e52-b95d-1a01cecacb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 10): \n",
    "    input_layer = tf.keras.layers.Input(shape = (X_train_word2vec.shape[1]))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(1)\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8153ea5-cefc-4075-994d-c51461505e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = train_omics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95a7d5f5-e03c-4de4-8bea-d4821cc7209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1, h2 = 16,16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2ff179a-2c64-4bae-bfd5-3ce7f4b40fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ann_15 = ann(h1)\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "# ann_15.summary()\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bf5144e-59f2-413e-af30-39407819094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 30)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                496       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 513\n",
      "Trainable params: 513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9c45b5a-9f13-4fd9-b90c-ed94e069b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = train_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bce5668e-a895-47b4-8f1c-6e5d1fd3c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_20 = ann(h2)\n",
    "\n",
    "\n",
    "\n",
    "# ann_20.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a41f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_1 = ann_15.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0721ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_2 = ann_20.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b2ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = total_weights_1 + total_weights_2 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "999f5e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1987"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "feb2ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch size\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4eea8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_weights = 0.08\n",
    "# var_targets = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b49ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a60a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import invgamma, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd888262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3355c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1ce82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7425ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7959ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1db4063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = ann_15.get_weights()\n",
    "weights_ann_2 = ann_20.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43a211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1): \n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "\n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "\n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, 1)\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "\n",
    "    n_hidden_2 = len(weights_ann_2[0].ravel())\n",
    "\n",
    "    initial_ensembles_1 = initial_ensembles.copy()[:, total_weights_1:(total_weights_1+ total_weights_2)]\n",
    "\n",
    "    hidden_weights_2 = initial_ensembles_1[:,:n_hidden_2].reshape(size_ens, batch_data1.shape[1], h2)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_2 = np.einsum('ij,kjl->kil', batch_data1, hidden_weights_2)\n",
    "\n",
    "    hidden_layer_bias_2 = initial_ensembles[:,n_hidden_2:(n_hidden_2 + h2)].reshape(size_ens, 1,  h2)\n",
    "\n",
    "    hidden_output_2 = hidden_output_2+ hidden_layer_bias_2\n",
    "\n",
    "    n_pred_weights_2 = len(weights_ann_2[2].ravel())\n",
    "\n",
    "    output_weights_2 = initial_ensembles_1[:,(n_hidden_2 + h2):(n_hidden_2 + h2 + n_pred_weights_2) ].reshape(size_ens, h2, 1)\n",
    "\n",
    "\n",
    "    output_2 = np.einsum('ijk,ikl->ijl', hidden_output_2, output_weights_2)\n",
    "\n",
    "\n",
    "    output_layer_bias_2 = initial_ensembles_1[:,(n_hidden_2 + h2 + n_pred_weights_2):(n_hidden_2 + h2 + n_pred_weights_2 + 1)].reshape(size_ens, 1, 1)\n",
    "\n",
    "\n",
    "    final_output_2 = output_2 + output_layer_bias_2\n",
    "\n",
    "\n",
    "    weights_1 = initial_ensembles[:, :total_weights_1]\n",
    "\n",
    "    weights_2 = initial_ensembles[:, total_weights_1:(total_weights_1 + total_weights_2)]\n",
    "\n",
    "\n",
    "    avg_weights = initial_ensembles[:, -1].reshape(-1,1)\n",
    "\n",
    "    avg_weights_sig = expit(avg_weights)\n",
    "    \n",
    "    avg_weights_sig = avg_weights_sig.reshape(avg_weights_sig.shape[0], 1, avg_weights_sig.shape[1])\n",
    "    \n",
    "    complement_weights_sig = 1 - expit(avg_weights)\n",
    "    \n",
    "    complement_weights_sig = complement_weights_sig.reshape(complement_weights_sig.shape[0], 1, complement_weights_sig.shape[1])\n",
    "\n",
    "    final_output_1 = final_output_1*complement_weights_sig\n",
    "    \n",
    "    final_output_2 = final_output_2*avg_weights_sig\n",
    "    \n",
    "    output_1_ravel = final_output_1.reshape(size_ens, final_output_1.shape[1]*final_output_1.shape[2])\n",
    "\n",
    "    output_2_ravel = final_output_2.reshape(size_ens, final_output_2.shape[1]*final_output_2.shape[2])\n",
    "\n",
    "\n",
    "    output_1_ravel = output_1_ravel\n",
    "\n",
    "    output_2_ravel = output_2_ravel\n",
    "\n",
    "\n",
    "\n",
    "    weights_1_add = np.zeros((size_ens, (total_weights_2 - total_weights_1)))\n",
    "\n",
    "\n",
    "\n",
    "    weights_1 = np.hstack((weights_1, weights_1_add))\n",
    "    \n",
    "\n",
    "\n",
    "    stack_1 = np.hstack((output_1_ravel, weights_1, np.repeat(0, size_ens).reshape(-1,1), np.repeat(0, size_ens).reshape(-1,1)))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    stack_2 = np.hstack((output_2_ravel, weights_2, avg_weights, log_sigma_points_1))\n",
    "\n",
    "    \n",
    "    initial_aug_state = np.hstack((stack_1, stack_2)) \n",
    "    \n",
    "\n",
    "    return initial_aug_state , output_1_ravel, output_2_ravel, log_sigma_points_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e3ef6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0eabfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b982682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_weights =0.5\n",
    "# var_weights_vec = 4\n",
    "# var_targets = 0.04\n",
    "# var_weights = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10d77915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2a6de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 6\n",
    "# reduction = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "471e3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_needed = (total_weights + 2*batch_size*1 + 1 + (total_weights_2 - total_weights_1))//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63796187",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = shape_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6aee42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = int(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc234219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebeb0869-7f0b-4f21-be63-0234896af39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fudged_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23d87ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f5427e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be0ee1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb492324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_train_logits_second[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c2dbaec-3249-404a-9971-c2fc17f68356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cf12935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef051014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07cb7b8c-4634-46e7-ab75-e865c7116995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_lstm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f0e5cb1-4067-46ba-9399-ca30548a10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction = 8\n",
    "# var_weights = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "197043a4-b420-4e3b-beaf-699cd7c3db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_idx = 16\n",
    "# np.log(catch_test_probs[cur_idx]/(1-catch_test_probs[cur_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ae6c226-20d1-4a84-ab7b-5c5295748826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75f0d45e-6b06-4e9a-8997-5217ab99ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = [i for i in range(0, catch_test_probs[cur_idx].shape[0]) if catch_test_probs[cur_idx][i] < 0.5]\n",
    "# ids_more = [i for i in range(0, catch_test_probs[cur_idx].shape[0]) if catch_test_probs[cur_idx][i] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f15dc9d-a59f-4ef8-b93a-8244896352c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1cebfd75-9077-4677-a4f7-05c09ac9f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "22ee79ea-e013-4f80-920e-10e2aeb0eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1969c78b-c105-482a-a957-e81329037a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cores = multiprocessing.cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5e25a8d-c51c-4c1d-9589-5b3b01f267e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cores = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b9d651b2-15fa-4542-84ab-106c958569cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('first_lstm_with_doc2vec_lstm_var_0.0001_real_world.pkl', 'rb') as f:\n",
    "#     first_lstm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2f12bf17-643b-4c5b-a2b0-d1f59b99557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 200\n",
    "# cutoff_threshold = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "407034e6-5a33-4332-b56c-f85cd2377b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1 = first_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e343ffb7-87d1-4974-a13f-d9a26c8a0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "881d1612-f98f-4df6-89b0-90bd2e97de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b48eef68-6ec3-4209-a725-e35ab84df90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "855a536b-0f7a-4066-8a38-124a19b9f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ac0108fa-359e-4d88-ba02-776a6f19b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6cd29e03-d778-4eeb-98b5-de815840cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fa106e5e-7f8f-4620-9a16-43194267fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_param = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "75c12e9a-898a-45db-9ee2-eb652adfbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_one_real_world(idx, inflation_factor = 0.2, cutoff = 100): \n",
    "    catch_1 = []\n",
    "    catch_2 = []\n",
    "    catch_3 = []\n",
    "    catch_4 = []\n",
    "    catch_5 = []\n",
    "#     from scipy.special import expit\n",
    "    patience_smaller = 0\n",
    "    patience_uns = 0\n",
    "# patience_bigger = 0\n",
    "\n",
    "#     best_train_acc = 0\n",
    "#     best_valid_acc = 1000\n",
    "\n",
    "#     best_valid_mae = 10\n",
    "    \n",
    "    best_train_width = 100000\n",
    "    \n",
    "    path = os.getcwd() + \"//dataset_\" + str(idx + 1) + \"/\"\n",
    "\n",
    "    ## read in all the drug features\n",
    "    ## for train test and valid\n",
    "    train_drugs = np.load(path + \"//\" + \"train_drug.npy\")\n",
    "    valid_drugs = np.load(path + \"//\" + \"valid_drug.npy\")\n",
    "    test_drugs = np.load(path + \"//\" + \"test_drug.npy\")\n",
    "\n",
    "    ## read in all the omics features\n",
    "    ## for train test and valid\n",
    "    train_omics = np.load(path + \"//\" + \"train_omics.npy\")[:,:30]\n",
    "    valid_omics = np.load(path + \"//\" + \"valid_omics.npy\")[:,:30]\n",
    "    test_omics = np.load(path + \"//\" + \"test_omics.npy\")[:,:30]\n",
    "\n",
    "    ## read in all the labels \n",
    "    ## for train test and valid\n",
    "    y_train = np.load(path + \"//\" + \"train_y.npy\")\n",
    "    y_valid = np.load(path + \"//\" + \"valid_y.npy\")\n",
    "    y_test = np.load(path + \"//\" + \"test_y.npy\")\n",
    "    \n",
    "    X_train_logits = y_train.reshape(-1,1)\n",
    "#     X_train_logits = catch_train_logits_second[idx]\n",
    "    \n",
    "    X_valid_logits = y_valid.reshape(-1,1)\n",
    "    X_test_logits = y_test.reshape(-1,1)\n",
    "    \n",
    "    ## create training batch chunks\n",
    "    train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "    batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "    ## generate some augmented variable for iteration 0\n",
    "    initial_aug_state_mean = np.repeat(0, total_weights)\n",
    "    initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "    initial_aug_state_cov = var_weights*np.identity((total_weights))\n",
    "    initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    exit_iter_no_thresh = 0\n",
    "    log_sigma_points_1 = (np.log(gamma(gamma_param, scale = 1/100).rvs(size_ens))).reshape(size_ens, 1)\n",
    "    \n",
    "\n",
    "#     y_train = catch_train_labels_second[idx]\n",
    "\n",
    "#     y_valid = catch_valid_labels_second[idx]\n",
    "\n",
    "#     y_test = catch_test_labels_second[idx]\n",
    "    \n",
    "    \n",
    "    train_lstm = train_omics\n",
    "    valid_lstm = valid_omics\n",
    "    # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "    test_lstm = test_omics\n",
    " \n",
    "\n",
    "    train_doc2vec = train_drugs\n",
    "    valid_doc2vec = valid_drugs\n",
    "    # valid_word2vec = catch[idx][7].iloc[catch_valid_idxes[idx],:].reset_index(drop = True)\n",
    "    test_doc2vec = test_drugs\n",
    "    \n",
    "    \n",
    "    \n",
    "    # train_valid_test_lstm = np.vstack((train_lstm, valid_lstm, test_lstm))\n",
    "    # train_valid_test_doc2vec = np.vstack((train_doc2vec, valid_doc2vec, test_doc2vec))\n",
    "    \n",
    "    # train_valid_test_lstm = np.vstack((train_lstm, valid_lstm))\n",
    "    # train_valid_test_doc2vec = np.vstack((train_doc2vec, valid_doc2vec))    \n",
    "    \n",
    "    train_valid_lstm = (train_lstm)\n",
    "    train_valid_doc2vec = (train_doc2vec)\n",
    "\n",
    "    # best_width_train = 100\n",
    "    \n",
    "    # threshold_achieved = False\n",
    "    # satisfactory = False\n",
    "    # satisfactory_counter = 0\n",
    "    \n",
    "    \n",
    "    best_coverage_train = 0\n",
    "    \n",
    "    start = datetime.now()\n",
    "    \n",
    "    for iter1 in range(0,500):\n",
    "        random_idx = random.sample(range(train_valid_lstm.shape[0]), train_valid_lstm.shape[0])\n",
    "        train_valid_lstm =train_valid_lstm[random_idx, :]\n",
    "        train_valid_doc2vec = train_valid_doc2vec[random_idx, :]\n",
    "\n",
    "        for batch_idx in (batch_chunks):\n",
    "\n",
    "            batch_data = train_valid_lstm[batch_idx,:]\n",
    "            batch_data1 = train_valid_doc2vec[batch_idx,:]\n",
    "            # print(batch_data.shape)\n",
    "            batch_targets = X_train_logits[batch_idx,:]\n",
    "            \n",
    "            # print(batch_targets.shape)\n",
    "            \n",
    "            # batch_targets = batch_targets.ravel().reshape(-1,1)\n",
    "\n",
    "            column_mod_2_shape = total_weights_2 + batch_data.shape[0]*1 + 1 + 1\n",
    "        \n",
    "            H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "\n",
    "            current_aug_state, column_mod_1, column_mod_2, log_sigma_points_1 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            # print(current_aug_state.shape)\n",
    "            \n",
    "            \n",
    "            var_targets_vec = np.log(1 + np.exp(log_sigma_points_1))\n",
    "            \n",
    "            var_targets_vec = var_targets_vec\n",
    "            \n",
    "            # current_aug_state_var = np.cov(current_aug_state.T) + inflation_factor*np.identity(current_aug_state.shape[1])\n",
    "            \n",
    "            current_aug_state_var = np.cov(current_aug_state.T) \n",
    "            \n",
    "            G_t = np.array([1 , 1]).reshape(-1,1)\n",
    "            \n",
    "            scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "            temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "            temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "        \n",
    "            for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "                \n",
    "                var_targets1 = var_targets_vec[ensemble_idx,:]\n",
    "                \n",
    "                R_t = var_targets1*np.identity(batch_targets.shape[0])\n",
    "            \n",
    "                measurement_error = mvn(np.repeat(0,batch_targets.shape[0]), var_targets1*np.identity(batch_targets.shape[0])).rvs(1).reshape(-1,1)\n",
    "            \n",
    "                target_current = batch_targets + measurement_error\n",
    "                \n",
    "                # print(target_current.shape)\n",
    "                \n",
    "                K_t = temp1@np.linalg.inv(temp2 + R_t)\n",
    "                \n",
    "                # print(K_t.shape)\n",
    "\n",
    "                current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "        \n",
    "\n",
    "            weights_ann_1 = current_aug_state[:,batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]      \n",
    "\n",
    "            weights_ann_2 = current_aug_state[:,-(total_weights_2+1):-2]    \n",
    "\n",
    "            initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, current_aug_state[:,-2].reshape(-1,1)))\n",
    "            \n",
    "            log_sigma_points_1 = current_aug_state[:,-1].reshape(-1,1)\n",
    "               \n",
    "            avg_betas = expit(current_aug_state[:,-2])\n",
    "        \n",
    "            complement = 1-avg_betas\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(valid_lstm, valid_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, valid_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_train = initial_targets\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             ind = (X_train_logits_true >= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]) & (X_train_logits_true <= np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:])\n",
    "        \n",
    "            # initial_targets_softmax = expit(initial_targets)\n",
    "        \n",
    "            # initial_softmax_train = initial_targets_softmax\n",
    "            \n",
    "            initial_targets_train_mean = initial_targets_train.mean(0)\n",
    "            \n",
    "            li = np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_train, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width_train = np.mean(width)\n",
    "            \n",
    "            # interim = np.vstack((catch_train_probs[idx] , catch_valid_probs[idx] ))\n",
    "        \n",
    "            interim = (X_valid_logits)\n",
    "            \n",
    "            ind = (interim >= li) & (interim <= ui)\n",
    "            \n",
    "            coverage_train= np.mean(ind.ravel())  \n",
    "            \n",
    "            train_mae = np.sqrt(mean_squared_error(interim, initial_targets_train_mean))\n",
    "            # train_mae = np.sqrt(np.mean(np.abs(interim.ravel() - initial_targets_train_mean.ravel())**2))\n",
    "        \n",
    "            current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(test_lstm, test_doc2vec, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            initial_targets = initial_targets.reshape(size_ens, test_lstm.shape[0],1)\n",
    "            \n",
    "            initial_targets_test = initial_targets\n",
    "            \n",
    "            # initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "            initial_targets_test_mean = initial_targets_test.mean(0)\n",
    "            \n",
    "            li = np.percentile(initial_targets_test, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets_test, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width = np.mean(width)\n",
    "            \n",
    "            catch_test_probs = (X_test_logits)\n",
    "            \n",
    "            ind_test = (catch_test_probs >= li) & (catch_test_probs <= ui)\n",
    "               \n",
    "\n",
    "                        \n",
    "            coverage_test = np.mean(ind_test.ravel())    \n",
    "\n",
    "            # initial_targets_test_mean = initial_targets_train.mean(0)\n",
    "    \n",
    "            \n",
    "            test_mae = np.sqrt(mean_squared_error(catch_test_probs, initial_targets_test_mean))\n",
    "            \n",
    "            # test_mae = np.sqrt(np.mean(np.abs(catch_test_probs.ravel() - initial_targets_test_mean.ravel())**2))\n",
    "       \n",
    "        # print(avg_width_train, best_train_width, coverage_train)\n",
    "        \n",
    "#         print(\"epoch \"+ str(iter1))\n",
    "#         print(\"patience \"+ str(patience_smaller))\n",
    "#         print(\"train mae is \" + str(train_mae))\n",
    "#         print(\"test mae is \" + str(test_mae))\n",
    "        \n",
    "#         print(\"train coverage is \"+ str(coverage_train))\n",
    "#         print(\"train width is \" + str(avg_width_train))        \n",
    "#         print(\"test coverage is \"+ str(coverage_test))\n",
    "#         print(\"test width is \" + str(avg_width))\n",
    "#         print(\"drugs weight is \" + str(np.mean(complement)))\n",
    "        # print(\"threshold \" + str(threshold_achieved))\n",
    "              \n",
    "        \n",
    "        if iter1 == 0: \n",
    "            best_train_mae = train_mae\n",
    "            best_test_mae = test_mae\n",
    "            exit_iter_no_thresh = iter1\n",
    "            best_test_preds = initial_targets_test\n",
    "            patience_smaller = 0\n",
    "            best_train_coverage = coverage_train\n",
    "            best_test_coverage = coverage_test\n",
    "            best_train_width = avg_width_train\n",
    "            best_test_width = avg_width\n",
    "            best_drugs_weight = np.mean(complement)\n",
    "        \n",
    "        \n",
    "        if (avg_width_train < best_train_width) & (coverage_train > 0.75): \n",
    "#             cur_best_train_width = avg_width_train\n",
    "#             cur_best_test_width = avg_width\n",
    "\n",
    "#             cur_best_train_coverage = coverage_train\n",
    "#             cur_best_test_coverage = coverage_test \n",
    "#             cur_best_lstm_weight = np.mean(complement)\n",
    "            best_train_mae = train_mae\n",
    "            best_test_mae = test_mae\n",
    "            exit_iter_no_thresh = iter1\n",
    "            best_test_preds = initial_targets_test\n",
    "            patience_smaller = 0\n",
    "            best_train_coverage = coverage_train\n",
    "            best_test_coverage = coverage_test\n",
    "            best_train_width = avg_width_train\n",
    "            best_test_width = avg_width\n",
    "            best_drugs_weight = np.mean(complement)\n",
    "            # satisfactory = True\n",
    "            \n",
    "        else:\n",
    "            patience_smaller+=1\n",
    "            \n",
    "        if patience_smaller > threshold:\n",
    "            \n",
    "            break\n",
    "            \n",
    "        if (coverage_train < 0.4): \n",
    "            patience_uns+=1\n",
    "            \n",
    "        if (patience_uns > 3):            \n",
    "            \n",
    "            break\n",
    "            \n",
    "#     base_model = tf.keras.models.load_model(\"Real_World_LSTM_Models\" + \"//\" + \"Model_\" + str(idx))\n",
    "#     extract_model = tf.keras.models.Model(base_model.input, base_model.layers[-3].output)\n",
    "#     alginate_lstm_embs = extract_model(np.array(alginate_seqs))\n",
    "#     current_aug_state1, column_mod_11, column_mod_21, log_sigma_points_1 = get_targets_with_weights(alginate_lstm_embs, alginate_doc2vec_vecs, initial_ensembles, log_sigma_points_1)\n",
    "            \n",
    "#     initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "#     initial_targets = initial_targets.reshape(size_ens, alginate_doc2vec_vecs.shape[0],1)\n",
    "            \n",
    "#             # initial_targets_test = initial_targets\n",
    "            \n",
    "#     initial_targets_softmax = expit(initial_targets)    \n",
    "            \n",
    "#             # initial_targets_test_mean = initial_targets_softmax.mean(0)\n",
    "            \n",
    "#     li = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "#     ui = np.percentile(initial_targets_softmax, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "#     width = ui - li\n",
    "            \n",
    "#     avg_width_alginate = np.mean(width)                \n",
    "            \n",
    "            \n",
    "    print(best_test_mae, best_test_coverage, best_test_width, flush = True)\n",
    "    end = datetime.now()\n",
    "    total = (end- start)\n",
    "    time_taken = total.seconds/60.0\n",
    "    return best_train_mae, best_test_mae, best_train_coverage, best_train_width, best_test_coverage, best_test_width,  best_drugs_weight, exit_iter_no_thresh, time_taken, best_test_preds\n",
    "        \n",
    "    # print(\"something went awry\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "605540da-2ad3-4d18-b8a4-93dd7c052f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "138d0228-17b7-4019-9abe-458206e8a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_threshold = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "857196a6-5937-4318-97f8-d19c183afe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(y_train)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4dcabe4b-76ae-4302-8ada-218067cc7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d2a0a04c-eb2b-4dd6-938a-0558970523ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7008890313290297 0.99 12.849709672732194\n"
     ]
    }
   ],
   "source": [
    "best_train_mae, best_test_mae, best_train_coverage, best_train_width, best_test_coverage, best_test_width,  best_drugs_weight, exit_iter_no_thresh, time_taken, best_test_preds = rep_one_real_world(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "681ecfde-9fcb-41a3-81a4-0882608d25a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r\"/lustre/work/statgrads/vpiyush2/enkf_simulations/Old_Strategy_EnKF_LSTM_Doc2Vec_Simulations/DeepCDR/dataset_\" + str(1 + 1) + \"/\"\n",
    "# y_test = np.load(path + \"//\" + \"test_y.npy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "83f9fb37-8c23-4e94-b510-e4b993511756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "54638285-44a5-43c0-b375-294226feefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sqrt(mean_squared_error(best_test_preds.mean(0),  y_test.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1d588820-93dd-43b0-bcd2-695cc810935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_train_mae, best_test_mae, best_train_coverage, best_train_width, best_test_coverage,  best_test_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4ce50533-7f93-4dbc-98b9-2e662e1b4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f49b8b8c-0e52-4d0b-bb70-7d16ddf6d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sqrt(np.mean(y_test.reshape(-1,1)- best_test_preds.mean(0))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b6cf2a8d-b3bc-4c4b-b88d-61603cd5c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_test_preds.mean(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "46f0b80b-4912-4283-b031-8710cd57c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(y_test.reshape(-1,1), best_test_preds.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ef0d0eb2-8069-4943-aa25-40da68911a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sqrt(np.mean((y_test-best_test_preds.mean(0))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ee5daf3b-e8eb-4405-9a8b-1f2b2c5ebb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_test_preds.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "99a723c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4631526130469177 0.99 13.826083302636633\n",
      "2.930730772235116 0.93 10.293535434416288\n",
      "2.804955039126143 0.93 10.327234638932463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:  2.0min remaining:  4.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.31147179146448 0.95 9.601683169840221\n",
      "2.2813092250787625 1.0 13.147938111967898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   5 out of  10 | elapsed:  2.1min remaining:  2.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11465577933989 0.97 11.59590749017658\n",
      "3.1259858194128234 0.98 13.651759704435358\n",
      "2.1084743991866377 0.78 6.041518925193459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   7 out of  10 | elapsed:  2.5min remaining:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.293299289360535 0.66 3.9766436569764476\n",
      "1.8145593252498566 0.84 5.8240456610150275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "catch_coverages = Parallel(n_jobs=10, verbose = 10, backend = \"loky\")(delayed(rep_one_real_world)(i) for i in range(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3c950c80-c06d-42f5-938a-699658ddee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string = \"Real_World_EnKF_DeepCDR_\" + \"Neurons_\" + str(h1)  + \"_Gamma_\" +  str(gamma_param) +  \"_var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c54e559f-315e-4d51-a113-effe6695dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"Real_World_EnKF_DeepCDR_\" + \"Neurons_\" + str(h1)  + \"_Gamma_\" +  str(gamma_param) +  \"_var_weights_\" + str(var_weights) + \"_num_ens_\" + str(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4213b5a0-b128-4d90-8eaf-ef7058c2e38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Real_World_EnKF_DeepCDR_Neurons_16_Gamma_500_var_weights_0.5_num_ens_534'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e0f11d9-de11-4880-be84-4340352ce23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(string + \".pkl\", 'wb') as f:\n",
    "    pickle.dump(catch_coverages, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1e8200e5-b784-49c8-9ae9-fd7ee5a2e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "647980a7-9ae3-4c5c-b25c-2e37b6a84679",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(catch_coverages).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e061792a-e589-486e-b8d2-336622f6bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fa101efc-351b-4645-87a3-f008abf1ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77536655-0afd-4976-980a-fa7a28b55201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\", \"avg_ci_width_train\", \"avg_ci_width_test\", \"avg_lstm_weight\", \"exit_iter\", \"exit_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cd8cefbd-9076-469e-a5dc-dc4637846308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.409395</td>\n",
       "      <td>1.814559</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6.305636</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5.824046</td>\n",
       "      <td>0.509393</td>\n",
       "      <td>2</td>\n",
       "      <td>3.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.467920</td>\n",
       "      <td>2.114656</td>\n",
       "      <td>0.87</td>\n",
       "      <td>9.334234</td>\n",
       "      <td>0.97</td>\n",
       "      <td>11.595907</td>\n",
       "      <td>0.540132</td>\n",
       "      <td>0</td>\n",
       "      <td>2.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.619765</td>\n",
       "      <td>2.804955</td>\n",
       "      <td>0.87</td>\n",
       "      <td>9.057397</td>\n",
       "      <td>0.93</td>\n",
       "      <td>10.327235</td>\n",
       "      <td>0.454207</td>\n",
       "      <td>0</td>\n",
       "      <td>1.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.311016</td>\n",
       "      <td>2.293299</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5.208020</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3.976644</td>\n",
       "      <td>0.494393</td>\n",
       "      <td>1</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.824174</td>\n",
       "      <td>3.125986</td>\n",
       "      <td>1.00</td>\n",
       "      <td>11.783717</td>\n",
       "      <td>0.98</td>\n",
       "      <td>13.651760</td>\n",
       "      <td>0.479499</td>\n",
       "      <td>0</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.795989</td>\n",
       "      <td>2.463153</td>\n",
       "      <td>0.94</td>\n",
       "      <td>12.033811</td>\n",
       "      <td>0.99</td>\n",
       "      <td>13.826083</td>\n",
       "      <td>0.487724</td>\n",
       "      <td>0</td>\n",
       "      <td>1.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.354518</td>\n",
       "      <td>2.311472</td>\n",
       "      <td>0.94</td>\n",
       "      <td>9.330114</td>\n",
       "      <td>0.95</td>\n",
       "      <td>9.601683</td>\n",
       "      <td>0.384552</td>\n",
       "      <td>0</td>\n",
       "      <td>1.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.491844</td>\n",
       "      <td>2.930731</td>\n",
       "      <td>0.94</td>\n",
       "      <td>9.126487</td>\n",
       "      <td>0.93</td>\n",
       "      <td>10.293535</td>\n",
       "      <td>0.541473</td>\n",
       "      <td>0</td>\n",
       "      <td>1.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.829252</td>\n",
       "      <td>2.281309</td>\n",
       "      <td>0.98</td>\n",
       "      <td>12.414253</td>\n",
       "      <td>1.00</td>\n",
       "      <td>13.147938</td>\n",
       "      <td>0.484440</td>\n",
       "      <td>0</td>\n",
       "      <td>1.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.127707</td>\n",
       "      <td>2.108474</td>\n",
       "      <td>0.83</td>\n",
       "      <td>5.486479</td>\n",
       "      <td>0.78</td>\n",
       "      <td>6.041519</td>\n",
       "      <td>0.499796</td>\n",
       "      <td>1</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1     2          3     4          5         6  7         8\n",
       "0  2.409395  1.814559  0.80   6.305636  0.84   5.824046  0.509393  2  3.083333\n",
       "1  2.467920  2.114656  0.87   9.334234  0.97  11.595907  0.540132  0  2.066667\n",
       "2  2.619765  2.804955  0.87   9.057397  0.93  10.327235  0.454207  0  1.833333\n",
       "3  2.311016  2.293299  0.84   5.208020  0.66   3.976644  0.494393  1  2.500000\n",
       "4  2.824174  3.125986  1.00  11.783717  0.98  13.651760  0.479499  0  2.333333\n",
       "5  2.795989  2.463153  0.94  12.033811  0.99  13.826083  0.487724  0  1.716667\n",
       "6  2.354518  2.311472  0.94   9.330114  0.95   9.601683  0.384552  0  1.950000\n",
       "7  2.491844  2.930731  0.94   9.126487  0.93  10.293535  0.541473  0  1.833333\n",
       "8  2.829252  2.281309  0.98  12.414253  1.00  13.147938  0.484440  0  1.983333\n",
       "9  2.127707  2.108474  0.83   5.486479  0.78   6.041519  0.499796  1  2.333333"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4fc1dcac-24b2-45e7-ae4c-e55eca90a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check.columns = [\"train_mae\", \"test_mae\", \"train_coverage\", \"train_width\", \"test_coverage\", \"test_width\", \"exit_iter\", \"time_taken\", \"avg_width_alginate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dc699633-60c4-4774-93ef-e90160803672",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.columns = [\"train_mae\", \"test_mae\", \"train_coverage\", \"train_width\", \"test_coverage\", \"test_width\", \"drugs_weight\", \"exit_iter\", \"time_taken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "103b1436-15fd-4e1f-800f-700817b41ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_mae         2.523158\n",
       "test_mae          2.424859\n",
       "train_coverage    0.901000\n",
       "train_width       9.008015\n",
       "test_coverage     0.903000\n",
       "test_width        9.828635\n",
       "drugs_weight      0.487561\n",
       "exit_iter         0.400000\n",
       "time_taken        2.163333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2a69771d-fd51-41a0-a90f-e012604617e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_mae          2.479882\n",
       "test_mae           2.302386\n",
       "train_coverage     0.905000\n",
       "train_width        9.228300\n",
       "test_coverage      0.940000\n",
       "test_width        10.310385\n",
       "drugs_weight       0.491059\n",
       "exit_iter          0.000000\n",
       "time_taken         2.025000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fcf483cf-1d09-4d5d-8c7c-7db62473a356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_mae         2.523158\n",
       "test_mae          2.424859\n",
       "train_coverage    0.901000\n",
       "train_width       9.008015\n",
       "test_coverage     0.903000\n",
       "test_width        9.828635\n",
       "drugs_weight      0.487561\n",
       "exit_iter         0.400000\n",
       "time_taken        2.163333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "35a4171e-96bc-46c1-82d6-4f8e73f99dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean = check.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b4303826-48ff-4077-ae66-d048f1ee8a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mean.to_csv(\"Mean_Metrics_\" +  string +  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9b520f45-ad8d-453c-80e7-7a6bb711692f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_mae         0.239182\n",
       "test_mae          0.410012\n",
       "train_coverage    0.067897\n",
       "train_width       2.642244\n",
       "test_coverage     0.110156\n",
       "test_width        3.494089\n",
       "drugs_weight      0.044896\n",
       "exit_iter         0.699206\n",
       "time_taken        0.411246\n",
       "dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6fca625b-cf9b-4fac-865e-79dfb96918af",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std = check.std().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a644ab46-27f8-472c-912e-de07bbd1223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_std.to_csv(\"Std_Metrics_\" + string +  \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e3e43629-3a74-4d41-acaf-dea297a3840c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_mae         0.023918\n",
       "test_mae          0.041001\n",
       "train_coverage    0.006790\n",
       "train_width       0.264224\n",
       "test_coverage     0.011016\n",
       "test_width        0.349409\n",
       "drugs_weight      0.004490\n",
       "exit_iter         0.069921\n",
       "time_taken        0.041125\n",
       "dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.std()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a83c3d12-b2f0-44b8-9904-7b10c4f513bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = []\n",
    "# enkf_preds = []\n",
    "# for i in range(0,reps):\n",
    "#     all_preds = catch_coverages[i][-1]\n",
    "#     all_preds = all_preds.mean(0)\n",
    "#     catch_test_probs = expit(catch1[i][2])\n",
    "#     true_probs = catch_test_probs.ravel().tolist()\n",
    "#     true_preds.append(true_probs)\n",
    "#     enkf_preds.append(all_preds.ravel().tolist())\n",
    "#     # plt.scatter(true_probs, all_preds.ravel().tolist())\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4089a2ab-43f9-4e24-a7ed-add7bdc14156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = [inner for item in true_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "65492b8d-d7e4-4375-8577-d79a633680b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkf_preds = [inner for item in enkf_preds for inner in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "19776731-14c7-43c3-bd48-163aa67e2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(np.abs(np.array(true_preds)-np.array(enkf_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1ebada74-6fe8-4f58-a939-87ca7399aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(enkf_preds,true_preds, alpha=0.5)\n",
    "# plt.xlabel(\"EnKF Predictions\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.ylabel(\"LSTM Predictions\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.xticks( fontsize = 10, fontweight = \"bold\")\n",
    "# plt.yticks( fontsize = 10, fontweight = \"bold\")\n",
    "# plt.axline((0, 0), slope=1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dd706672-8fd1-4f54-88a2-d377f1b2d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ead27b05-299e-49dc-bb97-236a18cd05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_preds = []\n",
    "# for i in range(0, catch_coverages[cur_idx][-1].shape[1]):\n",
    "#     enkf_preds = catch_coverages[cur_idx][-1][:,i,:]\n",
    "#     enkf_preds_df = pd.DataFrame(enkf_preds)\n",
    "#     enkf_preds_df[\"Test_Sample_ID\"] = i \n",
    "#     enkf_preds_df.columns = [\"EnKF_Preds\", \"Test_Sample_ID\"]\n",
    "#     catch_preds.append(enkf_preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "76f88a3c-8152-4b54-8eea-761701d7b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_preds_df = pd.concat(catch_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6614c144-29c3-451d-a6c6-a624aa4096a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "45f52dcf-cc5b-4af0-b495-9c0601729154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = expit(catch1[cur_idx][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "51405252-c830-4c95-90d8-e42cffcae59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.figure(figsize = (10,10))\n",
    "# fig = sns.boxplot(catch_preds_df, x=\"Test_Sample_ID\", y=\"EnKF_Preds\", showfliers=False)\n",
    "# plt.scatter(range(0, filtered_df.shape[0]), filtered_df, c = \"black\", s = 50)\n",
    "# plt.xlabel(\"Test Sample ID\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.ylabel(\"EnKF Predictions\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.xticks(fontsize = 10, fontweight = \"bold\")\n",
    "# plt.yticks(fontsize = 10, fontweight = \"bold\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ab4ef63f-a716-4006-8923-39df160647d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = [i for i in range(0, filtered_df.shape[0]) if filtered_df[i] < 0.5]\n",
    "# ids_more = [i for i in range(0, filtered_df.shape[0]) if filtered_df[i] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0976b8bc-6faa-4c8e-a9d1-3b666d9435e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_preds_df.groupby(\"Test_Sample_ID\").quantile(q = [0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "64886e1a-d858-4ea8-9cc4-51ab0b072286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_preds_df_filtered = catch_preds_df[catch_preds_df[\"Test_Sample_ID\"].isin(ids_more)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6ecec8de-d825-4191-9f35-705382466d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_true = filtered_df[ids_more,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "860a9f6b-a286-4855-8530-2c2d71d08737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.figure(figsize = (10,10))\n",
    "# fig = sns.boxplot(catch_preds_df_filtered, x=\"Test_Sample_ID\", y=\"EnKF_Preds\", showfliers=False)\n",
    "# plt.scatter(range(0, filtered_true.shape[0]), filtered_true, c = \"black\", s = 50)\n",
    "# plt.xlabel(\"Test Sample ID\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.ylabel(\"EnKF Predictions\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.xticks(fontsize = 10, fontweight = \"bold\")\n",
    "# plt.yticks(fontsize = 10, fontweight = \"bold\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ec177a9b-74aa-4458-a88e-a8b1ab1deff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_preds_df_filtered = catch_preds_df[catch_preds_df[\"Test_Sample_ID\"].isin(ids)]\n",
    "# filtered_true = filtered_df[ids,:]\n",
    "# # plt.figure(figsize = (10,10))\n",
    "# fig = sns.boxplot(catch_preds_df_filtered, x=\"Test_Sample_ID\", y=\"EnKF_Preds\", showfliers=False)\n",
    "# plt.scatter(range(0, filtered_true.shape[0]), filtered_true, c = \"black\")\n",
    "# plt.xlabel(\"Test Sample ID\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.ylabel(\"EnKF Predictions\", fontsize = 15, fontweight = \"bold\")\n",
    "# plt.xticks(fontsize = 10, fontweight = \"bold\")\n",
    "# plt.yticks(fontsize = 10, fontweight = \"bold\")\n",
    "# plt.show()\n",
    "# # plt.ylim((0.9,1.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
